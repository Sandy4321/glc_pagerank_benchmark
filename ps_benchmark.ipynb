{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking the Predictive Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">Start by setting your S3 path!!!</h1>\n",
    "\n",
    "The predictive service needs a location for saving its configuration and state: nodes will be reading data from this location. This notebook will deploy on S3, so naturally this shared location will be an S3 path. If you were deploying on-premises, you'd be using some shared network location.\n",
    "\n",
    "Please set the s3_path to a bucket to which you can write using your configured AWS credentials! Below is my path - you won't be able to read/write to it so change it to something on your bucket space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3_path = \"s3://gl-guyrap-testing/ps_benchmark\" # You should create an empty S3 bucket/path ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">End by uncommenting and running the last cell!!!</h1>\n",
    "\n",
    "I am assuming that after setting your `s3_path`, you'll just run all the cells. This will create a new predictive service on AWS - but it will not shut it down when you're finished (= you'll still get billed for it). **Go to the last cell, uncomment it and run the `deployment.terminate_service()` command to stop getting billed.**\n",
    "\n",
    "Of course - it'd be better for you to go through the entire notebook step by step. But I know you! `¯\\_(ツ)_/¯`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites and Setup\n",
    "\n",
    "GraphLab Create has to be installed. This notebook was tested with version 1.9.\n",
    "\n",
    "Apache Bench is a command line tool for benchmarking web services. It is part of the Apache HTTP Server package.\n",
    "The package can be [downloaded from Apache's website](http://httpd.apache.org/download.cgi). However, I'll be using Apache Bench for Mac [which is available here](https://github.com/radiospiel/ApacheBench-Lion/raw/master/ab).|\n",
    "\n",
    "Some configuration variables should be set in order to create the predictive service properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify GraphLab is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import graphlab # same import as in the predictive services documentation\n",
    "    gl = graphlab # my favourite alias\n",
    "    print graphlab.version\n",
    "except:\n",
    "    raise RuntimeError(\"GraphLab Create is missing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify AWS credentials are set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gl.aws.get_credentials()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify `ab` is available in the system path\n",
    "\n",
    "We'll be benchmarking the predictive services using Apache Bench. <a href=\"#Benchmark-using-Apache-Bench-(ab)\">Go to the relevant section below</a> for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    ab_present = os.system(\"which ab\") == 0\n",
    "except:\n",
    "    ab_present = False\n",
    "\n",
    "if ab_present:\n",
    "    print \"ab is present, benchmarking can continue!\"\n",
    "else:\n",
    "    print \"ab (Apache Bench) is missing! You can continue running the next cells, but benchmarking u\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Predictive Service on Amazon EC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point on, we'll be using code example from the user guide:\n",
    "https://dato.com/learn/userguide/deployment/pred-getting-started.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can change the following two variables.\n",
    "region = 'us-west-2' # may affect client-side latency - the round-trip time depends on distance from region\n",
    "instance_type = 'm3.xlarge' # may affect server-side latency and throughput - and also how much you'll pay :)\n",
    "\n",
    "ec2 = graphlab.deploy.Ec2Config(region=region,\n",
    "                                instance_type=instance_type)\n",
    "\n",
    "\"\"\"\n",
    "ec2 = graphlab.deploy.Ec2Config(region=region,\n",
    "                                instance_type=instance_type,\n",
    "                                aws_access_key_id='YOUR_ACCESS_KEY',\n",
    "                                aws_secret_access_key='YOUR_SECRET_KEY')\n",
    "\"\"\"\n",
    "\n",
    "ec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you had already deployed a service in the path, you can reconnect to it:\n",
    "# deployment = gl.deploy.predictive_service.load(s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deployment = graphlab.deploy.predictive_service.create(\n",
    "    name=\"ps-benchmark\",\n",
    "    ec2_config=ec2,\n",
    "    state_path = s3_path,\n",
    "    num_hosts=1,\n",
    "    description=\"benchmarking the predictive services\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path = \"recommender_movie_ratings\"\n",
    "if os.path.exists(model_path):\n",
    "    model = gl.load_model(model_path)\n",
    "else:\n",
    "    from urllib import urlretrieve\n",
    "    data_url = \"https://s3.amazonaws.com/dato-datasets/movie_ratings/sample.small\"\n",
    "    data_filename = data_url.rsplit(\"/\", 1)[-1]\n",
    "    if not os.path.exists(data_filename):\n",
    "        urlretrieve(data_url, data_filename)\n",
    "\n",
    "    data = graphlab.SFrame.read_csv(data_filename,delimiter='\\t',column_type_hints={'rating':int})\n",
    "    model = graphlab.popularity_recommender.create(data, 'user', 'movie', 'rating')\n",
    "    model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deployment.add('recs', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_recs = deployment.test_query('recs',\n",
    "                        method='recommend',\n",
    "                        data={ 'users': [ 'Jacob Smith' ] })\n",
    "print test_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deployment.apply_changes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recs = deployment.query('recs',\n",
    "                        method='recommend',\n",
    "                        data={ 'users': [ 'Jacob Smith' ] })\n",
    "print recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api_key = deployment.api_key\n",
    "load_balancer_dns_name = deployment._environment.load_balancer_dns_name\n",
    "query_endpoint = 'http://%s/query/recs' % (load_balancer_dns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curl_cmd = \"\"\"curl -u api_key:%s \\\n",
    "-d '{ \"data\": {\"method\": \"recommend\", \"data\": { \"users\": [ \"Jacob Smith\" ] } } }' \\\n",
    "%s\"\"\" % (api_key, query_endpoint)\n",
    "print curl_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! $curl_cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark using Apache Bench (`ab`)\n",
    "\n",
    "Apache Bench is a command line tool for benchmarking web services. It is part of the Apache HTTP Server package.\n",
    "\n",
    "The package can be downloaded from here:\n",
    "http://httpd.apache.org/download.cgi\n",
    "\n",
    "However, I'll be using Apache Bench for Mac which I obtained from:\n",
    "https://github.com/radiospiel/ApacheBench-Lion/raw/master/ab\n",
    "\n",
    "A nice tutorial for Apache Bench can be found here:\n",
    "https://www.petefreitag.com/item/689.cfm\n",
    "\n",
    "The benchmark is simple: make the same query many times, and see how good is the predictive service's throughput and latency.\n",
    "\n",
    "The request's json is first written to a text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "benchmark_request_data_filename = 'benchmark_request_data.txt'\n",
    "with open(benchmark_request_data_filename, 'wb') as f:\n",
    "    f.write('''{ \"data\": {\"method\": \"recommend\", \"data\": { \"users\": [ \"Jacob Smith\" ] } } }''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! cat 'benchmark_request_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "concurrent = 4\n",
    "nr_requests = 40\n",
    "if ab_present:\n",
    "    ab_cmd = \"! ab -A api_key:%s -p %s -T application/json -c %d -n %d %s\" % (\n",
    "        api_key,\n",
    "        benchmark_request_data_filename,\n",
    "        concurrent,\n",
    "        nr_requests,\n",
    "        query_endpoint\n",
    "    )\n",
    "else:\n",
    "    ab_cmd = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! $ab_cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminate the Predictive Service (release EC2 resources)\n",
    "\n",
    "Uncomment the following line and run this cell to terminate the predictive service. This will release (free) the EC2 instances, so your billing would stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# deployment.terminate_service()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
